{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch-3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFXNHrehm8KqcpnpLYhyT4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQwX6_TiR7b_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ff29dbc8-33d5-4b08-9977-7f753f72bacd"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "weights = tf.Variable(tf.random.normal([300, 200], stddev=0.5),\n",
        "                          name=\"weights\")\n",
        "\n",
        "weights_untrainable = tf.Variable(tf.random.normal([300, 200], stddev=0.5),\n",
        "                          name=\"weights\", trainable=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU9XnMN3TA2P",
        "colab_type": "text"
      },
      "source": [
        "`tf.random.normal ` produces a tensor initialized using a normal distribution with standard deviation 0.5\n",
        "\n",
        "---\n",
        "the size of the tensor i.e. `300, 200` indicates that the weights connect a layer with 300 neurons to a layer with 200 neurons\n",
        "\n",
        "---\n",
        "the `trainable` option results in gradients being automatically computed and applied to `weights`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEIZN549UD6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other common methods for creating tensors\n",
        "\n",
        "shape = [300, 200]\n",
        "sample_weights_zeros = tf.Variable(tf.zeros(shape, dtype=tf.float32, name=None))\n",
        "sample_weights_ones = tf.Variable(tf.ones(shape, dtype=tf.float32, name=None))\n",
        "samples_trunc_norm = tf.Variable(tf.random.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None))\n",
        "sample_rnd_uni = tf.Variable(tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None))\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6EmdM3KVE1Y",
        "colab_type": "text"
      },
      "source": [
        "when `tf.Variable` is called, three operations are added to the computation graph: the operation producing the tensor (e.g. `tf.zeros`), the `tf.assign` operation which initializes the tensor, and the variable operation (e.g. `weights`) which stores the current value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW_4T18tX01q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x represents a minibatch of data stored as float32s\n",
        "x = tf.placeholder(tf.float32, name=\"x\", shape=[None, 784])   # None indicates that x can be initialized with any number of samples, \n",
        "                                                              # 784 indicates that each data sample has 784 dimensions\n",
        "W = tf.Variable(tf.random.uniform([784, 10], -1, -1), name=\"W\") \n",
        "multiply = tf.matmul(x, W)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFeI6QKdVErk",
        "colab_type": "text"
      },
      "source": [
        "`tf.placeholder` enables creating the computation graph without data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJo_Z20QeCdq",
        "colab_type": "text"
      },
      "source": [
        "example below of reusing network and layer functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXbPHY6IZSBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd4b42f5-4546-477a-abee-ed141fd69889"
      },
      "source": [
        "tf.disable_v2_behavior()\n",
        "def layer(input, weight_shape, bias_shape):\n",
        "  weight_init = tf.random_uniform_initializer(minval=-1, maxval=1)\n",
        "  bias_init = tf.constant_initializer(value=0)\n",
        "  W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
        "  b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
        "  return tf.matmul(input, W) + b\n",
        "\n",
        "def sample_network(input):\n",
        "  with tf.variable_scope(\"layer_1\"):\n",
        "    output_1 = layer(input, [784, 100], [100])\n",
        "  with tf.variable_scope(\"layer_2\"):\n",
        "    output_2 = layer(output_1, [100, 50], [50])\n",
        "  with tf.variable_scope(\"layer_3\"):\n",
        "    output_3 = layer(output_2, [50, 10], [10])\n",
        "  return output_3\n",
        "\n",
        "i_1 = tf.placeholder(tf.float32, [1000, 784], name=\"i_1\")\n",
        "sample_network(i_1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'layer_3/add:0' shape=(1000, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELA2uAu7gjiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(x):\n",
        "  tf.constant_initializer(value=0)\n",
        "  W = tf.get_variable(\"W\", [784, 10], initializer=init)\n",
        "  b = tf.get_variable(\"b\", [10], initializer=init)\n",
        "  output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "  return output\n",
        "\n",
        "def loss(output, y):\n",
        "  dot_product = y * tf.log(output)\n",
        "  x_entropy = -tf.reduce_sum(dot_product, reduction_indices=1)\n",
        "  loss = tf.reduce_mean(x_entropy)\n",
        "  return loss\n",
        "\n",
        "def training(cost, global_step):\n",
        "  tf.scalar_summary(\"cost\", cost)\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "  train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "  return train_op\n",
        "\n",
        "def evaluate(output, y):\n",
        "  correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  return accuracy\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_epochs = 1000\n",
        "batch_size = 100\n",
        "display_step = 1\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  x = tf.placeholder(\"float\", [None, 784]) # Input has dimension of 784 i.e. images of shape 28*28\n",
        "  y = tf.placeholder(\"float\", [None, 10])  # Output consists of 10 classes\n",
        "  output = inference(x)\n",
        "  cost = loss(output, y)\n",
        "  global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "  train_op = training(cost, global_step)\n",
        "  eval_op = evaluate(output, y)\n",
        "  summary_op = tf.merge_all_summaries()\n",
        "  saver = tf.train.Saver()\n",
        "  sess = tf.Session()\n",
        "  summary_writer = tf.train.SummaryWriter(\"logistic_logs/\", graph_def=sess.graph_def)\n",
        "  init_op = tf.initialize_all_variableS()\n",
        "  sess.run(init_op)\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples/batch_size) # i.e. number of batches\n",
        "    for i in range(total_batch):\n",
        "      mbatch_x, mbatch_y = mnist.train.next_batch(batch_size)\n",
        "      feed_dict = {x: mbatch_x, y: mbatch_y}\n",
        "      sess.run(train_op, feed_dict=feed_dict)\n",
        "      minibatch_cost = sess.run(cost, feed_dict=feed_dict)\n",
        "      avg_cost += minibatch_cost/total_batch\n",
        "    # log per epoch\n",
        "    if epoch % display_step == 0:\n",
        "      val_feed_dict = {\n",
        "        x : mnist.validation.images,\n",
        "        y : mnist.validation.labels\n",
        "      }\n",
        "      accuracy = sess.run(eval_op, feed_dict=val_feed_dict)\n",
        "      summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
        "      summary_writer.add_summary(summary_str, sess.run(global_step))\n",
        "      saver.save(sess, \"logistic_logs/model-checkpoint\", global_step=global_step)\n",
        "  test_feed_dict = {\n",
        "      x : mnist.test.images,\n",
        "      y : mnist.test.labels\n",
        "  }\n",
        "  accuracy = sess.run(eval_op, feed_dict=test_feed_dict)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}